{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jcgarcia18-create/CInema-Aguilas-Uas/blob/main/proyecto_final_sistemas_distribuidos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZS7LenHuEDsb"
      },
      "source": [
        "# PROYECTO FINAL - SISTEMAS DISTRIBUIDOS\n",
        "## Recomendador de libros con PySpark + TF-IDF\n",
        "100 libros más descargados de Project Gutenberg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yA09gWS6EDse"
      },
      "execution_count": 1,
      "outputs": [],
      "source": [
        "# 1. Instalamos dependencias (solo la primera vez)\n",
        "!pip install pyspark beautifulsoup4 lxml -q"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqnTpHujEDsf"
      },
      "execution_count": 2,
      "outputs": [],
      "source": [
        "import re, os, requests\n",
        "from bs4 import BeautifulSoup\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, IDF, Normalizer\n",
        "\n",
        "# Stop any existing SparkSession to ensure a clean start\n",
        "try:\n",
        "    spark.stop()\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .appName(\"GutenbergRecommender\") \\\n",
        "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
        "    .config(\"spark.driver.memory\", \"4g\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "sc = spark.sparkContext"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBXP68--EDsf",
        "outputId": "001fbbd0-3d73-4008-fc22-78f541029db5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Descargado 84\n",
            "Descargado 2701\n",
            "Descargado 1342\n",
            "Descargado 1513\n",
            "Descargado 46\n",
            "Descargado 43\n",
            "Descargado 25344\n",
            "Descargado 8492\n",
            "Descargado 11\n",
            "Descargado 100\n",
            "Descargado 145\n",
            "Descargado 2641\n",
            "Descargado 2542\n",
            "Descargado 2554\n",
            "Descargado 37106\n",
            "Descargado 174\n",
            "Descargado 16328\n",
            "Descargado 1260\n",
            "Descargado 1080\n",
            "Descargado 844\n",
            "Descargado 345\n",
            "Descargado 64317\n",
            "Descargado 67979\n",
            "Descargado 76\n",
            "Descargado 16389\n",
            "Descargado 394\n",
            "Descargado 1661\n",
            "Descargado 4085\n",
            "Descargado 6593\n",
            "Descargado 2160\n",
            "Descargado 1259\n",
            "Descargado 98\n",
            "Descargado 6761\n",
            "Descargado 5197\n",
            "Descargado 33944\n",
            "Descargado 28054\n",
            "Descargado 768\n",
            "Descargado 3207\n",
            "Descargado 1400\n",
            "Descargado 5200\n",
            "Descargado 205\n",
            "Descargado 2591\n",
            "Descargado 1184\n",
            "Descargado 74\n",
            "Descargado 55\n",
            "Descargado 7370\n",
            "No se pudo descargar 36034 (status 404)\n",
            "Descargado 6130\n",
            "Descargado 4300\n",
            "No se pudo descargar 16119 (status 404)\n",
            "Descargado 3206\n",
            "Descargado 1998\n",
            "Descargado 2600\n",
            "Descargado 3296\n",
            "No se pudo descargar 5740 (status 404)\n",
            "Descargado 45\n",
            "Descargado 77373\n",
            "Descargado 1232\n",
            "Descargado 23\n",
            "Descargado 41445\n",
            "No se pudo descargar 4363 (status 404)\n",
            "Descargado 77369\n",
            "Descargado 2148\n",
            "Descargado 51461\n",
            "Descargado 829\n",
            "Descargado 1952\n",
            "Descargado 408\n",
            "Descargado 8800\n",
            "Descargado 27509\n",
            "Descargado 25162\n",
            "Descargado 120\n",
            "Descargado 1023\n",
            "Descargado 17135\n",
            "No se pudo descargar 19942 (status 404)\n",
            "Descargado 2852\n",
            "Descargado 514\n",
            "Descargado 26\n",
            "Descargado 1727\n",
            "No se pudo descargar 34901 (status 404)\n",
            "Descargado 1399\n",
            "Descargado 27558\n",
            "Descargado 779\n",
            "Descargado 72679\n",
            "Descargado 730\n",
            "Descargado 15399\n",
            "No se pudo descargar 18047 (status 404)\n",
            "Descargado 135\n",
            "Descargado 161\n",
            "Descargado 41\n",
            "Descargado 56517\n",
            "Descargado 57333\n",
            "Descargado 16\n",
            "No se pudo descargar 17199 (status 404)\n",
            "Descargado 77328\n",
            "Descargado 996\n",
            "Descargado 1524\n",
            "Descargado 24022\n",
            "Descargado 42324\n",
            "Descargado 110\n",
            "Descargado 2814\n"
          ]
        }
      ],
      "source": [
        "# 3. Descarga automática de los 100 libros más populares\n",
        "def descargar_top100():\n",
        "    url = \"https://www.gutenberg.org/browse/scores/top\"\n",
        "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "    soup = BeautifulSoup(requests.get(url, headers=headers).text, 'html.parser')\n",
        "\n",
        "    libros = []\n",
        "    for a in soup.find_all('a', href=True):\n",
        "        href = a['href']\n",
        "        if href.startswith('/ebooks/') and href[8:].isdigit():\n",
        "            libros.append(int(href[8:]))\n",
        "\n",
        "    top100 = libros[:100]\n",
        "    os.makedirs(\"books\", exist_ok=True)\n",
        "\n",
        "    for eid in top100:\n",
        "        txt_url = f\"https://www.gutenberg.org/files/{eid}/{eid}-0.txt\"\n",
        "        r = requests.get(txt_url, headers=headers)\n",
        "        if r.status_code == 200:\n",
        "            with open(f\"books/{eid}.txt\", \"wb\") as f:\n",
        "                f.write(r.content)\n",
        "            print(f\"Descargado {eid}\")\n",
        "        else:\n",
        "            print(f\"No se pudo descargar {eid} (status {r.status_code})\")\n",
        "\n",
        "descargar_top100()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQ5MuigrEDsg"
      },
      "execution_count": 4,
      "outputs": [],
      "source": [
        "# 4. Función de limpieza (elimina encabezado y pie de Gutenberg)\n",
        "def limpiar_gutenberg(texto):\n",
        "    inicio = texto.find(\"*** START OF THE PROJECT GUTENBERG EBOOK\")\n",
        "    if inicio == -1:\n",
        "        inicio = texto.find(\"***START OF THE PROJECT GUTENBERG EBOOK\")\n",
        "    fin = texto.rfind(\"*** END OF THE PROJECT GUTENBERG EBOOK\")\n",
        "    if fin == -1:\n",
        "        fin = texto.rfind(\"End of the Project Gutenberg EBook\")\n",
        "\n",
        "    if inicio != -1 and fin != -1:\n",
        "        texto = texto[inicio:fin]\n",
        "\n",
        "    # Normalización básica\n",
        "    texto = re.sub(r'[^a-zA-Z\\s]', ' ', texto.lower())\n",
        "    texto = re.sub(r'\\s+', ' ', texto).strip()\n",
        "    return texto"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlTYg55GEDsg",
        "outputId": "91e57b4d-bbaa-46ae-d339-97ff8d6adda0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------+--------------------------------------------------------------------------------+\n",
            "|       id|titulo|                                                                           texto|\n",
            "+---------+------+--------------------------------------------------------------------------------+\n",
            "|16389.txt| 16389|start of the project gutenberg ebook illustration the enchanted april by eliz...|\n",
            "|   46.txt|    46|start of the project gutenberg ebook a christmas carol a christmas carol in p...|\n",
            "| 6761.txt|  6761|start of the project gutenberg ebook the adventures of ferdinand count fathom...|\n",
            "|  514.txt|   514|start of the project gutenberg ebook little women little women by louisa may ...|\n",
            "|27509.txt| 27509|start of the project gutenberg ebook the cia world factbook contents countrie...|\n",
            "+---------+------+--------------------------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 5. Cargar y limpiar todos los libros\n",
        "def cargar_libros():\n",
        "    datos = []\n",
        "    for archivo in os.listdir(\"books\"):\n",
        "        if archivo.endswith(\".txt\"):\n",
        "            path = os.path.join(\"books\", archivo)\n",
        "            with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "                texto = f.read()\n",
        "            limpio = limpiar_gutenberg(texto)\n",
        "            # Intentamos obtener título del nombre (opcional)\n",
        "            titulo = archivo.replace(\".txt\", \"\")\n",
        "            datos.append((archivo, titulo, limpio))\n",
        "    return spark.createDataFrame(datos, [\"id\", \"titulo\", \"texto\"])\n",
        "\n",
        "df = cargar_libros()\n",
        "df.show(5, truncate=80)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynLkunvpEDsg"
      },
      "execution_count": 6,
      "outputs": [],
      "source": [
        "# 6. Preprocesamiento (tokenización + stop-words)\n",
        "tokenizer = Tokenizer(inputCol=\"texto\", outputCol=\"palabras\")\n",
        "df = tokenizer.transform(df)\n",
        "\n",
        "remover = StopWordsRemover(inputCol=\"palabras\", outputCol=\"filtradas\")\n",
        "df = remover.transform(df)\n",
        "\n",
        "# Filtrar palabras muy cortas\n",
        "filtrar_udf = udf(lambda palabras: [p for p in palabras if len(p) > 3], ArrayType(StringType()))\n",
        "df = df.withColumn(\"filtradas\", filtrar_udf(\"filtradas\"))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfTmhRAtEDsg",
        "outputId": "78229ed3-a02e-4b73-9c17-f43bf4555e4b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[id: string, titulo: string, texto: string, palabras: array<string>, filtradas: array<string>, tf: vector, tfidf: vector, norm: vector]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# 7. CountVectorizer + TF-IDF\n",
        "cv = CountVectorizer(inputCol=\"filtradas\", outputCol=\"tf\", vocabSize=20000, minDF=2)\n",
        "cv_model = cv.fit(df)\n",
        "df_tf = cv_model.transform(df)\n",
        "\n",
        "idf = IDF(inputCol=\"tf\", outputCol=\"tfidf\")\n",
        "idf_model = idf.fit(df_tf)\n",
        "df_tfidf = idf_model.transform(df_tf)\n",
        "\n",
        "# Normalización L2 (para similitud coseno)\n",
        "normalizer = Normalizer(inputCol=\"tfidf\", outputCol=\"norm\", p=2.0)\n",
        "df_final = normalizer.transform(df_tfidf)\n",
        "\n",
        "df_final.cache()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btyeGWsgEDsh"
      },
      "execution_count": 8,
      "outputs": [],
      "source": [
        "# 8. FUNCIÓN: Recomendar N libros similares\n",
        "import numpy as np\n",
        "from pyspark.sql.types import DoubleType\n",
        "\n",
        "def recomendar(id_o_titulo, n=5):\n",
        "    # Buscar el libro por id de archivo o por título\n",
        "    query = df_final.filter((col(\"id\") == id_o_titulo) | (col(\"titulo\") == id_o_titulo))\n",
        "    if query.count() == 0:\n",
        "        print(\"Libro no encontrado\")\n",
        "        return\n",
        "\n",
        "    fila_query = query.select(\"titulo\", \"norm\").collect()[0]\n",
        "    nombre = fila_query[\"titulo\"]\n",
        "    vector_query = fila_query[\"norm\"].toArray()\n",
        "\n",
        "    # Enviamos el vector de consulta a todos los workers\n",
        "    bc_vec = sc.broadcast(vector_query)\n",
        "\n",
        "    # UDF para calcular el producto punto con el vector de consulta\n",
        "    def dot_with_query(v):\n",
        "        if v is None:\n",
        "            return 0.0\n",
        "        return float(np.dot(v.toArray(), bc_vec.value))\n",
        "\n",
        "    dot_udf = udf(dot_with_query, DoubleType())\n",
        "\n",
        "    similitudes = df_final.withColumn(\"sim\", dot_udf(col(\"norm\")))\n",
        "\n",
        "    resultado = similitudes.filter(col(\"titulo\") != nombre) \\\n",
        "        .orderBy(col(\"sim\").desc()) \\\n",
        "        .select(\"titulo\", \"sim\") \\\n",
        "        .limit(n)\n",
        "\n",
        "    print(f\"Si te gusta: {nombre}\")\n",
        "    print(\"Te recomendamos:\")\n",
        "    for fila in resultado.collect():\n",
        "        print(f\"   → {fila.titulo} (sim: {fila.sim:.4f})\")\n",
        "\n",
        "    return resultado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uc8GIiTvEDsh"
      },
      "execution_count": 11,
      "outputs": [],
      "source": [
        "# 9. FUNCIÓN: M palabras más características (versión corregida y con títulos)\n",
        "def palabras_clave_por_titulo(titulo_busqueda, m=10):\n",
        "    fila = df_final.filter(col(\"titulo\") == titulo_busqueda).collect()\n",
        "    if not fila:\n",
        "        print(\"Título no encontrado\")\n",
        "        return\n",
        "\n",
        "    fila = fila[0]\n",
        "    vector = fila[\"tfidf\"]\n",
        "    vocab = cv_model.vocabulary\n",
        "\n",
        "    # Convertir índices a enteros normales (corrección del error numpy.int32)\n",
        "    pesos = [(float(vector[int(i)]), vocab[int(i)]) for i in vector.indices]\n",
        "\n",
        "    # Ordenar por mayor peso TF-IDF\n",
        "    top = sorted(pesos, reverse=True)[:m]\n",
        "\n",
        "    print(f\"Palabras clave de: {titulo_busqueda}\")\n",
        "    for peso, palabra in top:\n",
        "        print(f\"   {palabra}: {peso:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5LFYn2DEDsh",
        "outputId": "d5af41dc-8e68-4cd9-d2df-777a96003c46"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RECOMENDACIONES\n",
            "Si te gusta: 1342\n",
            "Te recomendamos:\n",
            "   → 84 (sim: 0.1094)\n",
            "   → 42324 (sim: 0.1085)\n",
            "   → 41445 (sim: 0.1079)\n",
            "   → 1260 (sim: 0.1053)\n",
            "   → 768 (sim: 0.0637)\n",
            "   → 4085 (sim: 0.0468)\n",
            "   → 2160 (sim: 0.0400)\n",
            "\n",
            "PALABRAS CLAVE\n",
            "Palabras clave de: 84\n",
            "   clerval: 185.6320\n",
            "   justine: 142.2679\n",
            "   elizabeth: 104.0890\n",
            "   felix: 88.0005\n",
            "   frankenstein: 84.9502\n",
            "   safie: 78.6576\n",
            "   geneva: 59.1202\n",
            "   agatha: 51.3782\n",
            "   ingolstadt: 50.3409\n",
            "   cottagers: 45.2560\n"
          ]
        }
      ],
      "source": [
        "# 10. EJEMPLOS REALES\n",
        "print(\"RECOMENDACIONES\")\n",
        "recomendar(\"1342.txt\", n=7)  # Pride and Prejudice (mantiene archivo)\n",
        "\n",
        "print(\"\\nPALABRAS CLAVE\")\n",
        "palabras_clave_por_titulo(\"84\")  # Frankenstein\n"
      ]
    }
  ]
}